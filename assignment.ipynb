{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "- WSL\n",
    "- Miniconda3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment\n",
    "- Create conda env `conda create langchain python=3.11`\n",
    "- Install the ipykernel into langchain conda env with `conda install -n langchain ipykernel --update-deps --force-reinstall`\n",
    "- Set the \"langchain\" env that has been just created as the running env in VS code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install langchain and openai package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain==0.3.2 openai==1.51.0 python-dotenv==1.0.1 langchain-openai==0.2.2 langchain-community==0.3.0 pypdf==5.0.1 chromadb==0.5.11 duckduckgo-search==6.2.13 numexpr==2.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to set value of `OPENAI_API_KEY` that you get from the training team in the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_VERSION = \"2024-06-01\"\n",
    "OPENAI_MODEL_NAME = \"gpt-4o\"\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overviews\n",
    "The BonBon FAQ.pdf file contains frequently asked questions and answers for customer support scenario. The topics are around IT related issue troubleshooting such as networking, software, hardware. You are requested to provide a solution to build a chat bot capable of answering the user questions with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Document Indexing (mandatory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The content of BonBon FAQ.pdf should be indexed to the local Chroma vector DB from where the chatbot can lookup the appropriate information to answer questions.\n",
    "- Should use some embedding model such as Azure Open AI text-embedding-ada-002 to create vectors, feel free to use any other open source embedding model if it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# setup embedding model\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=OPENAI_ADA_EMBEDDING_DEPLOYMENT,\n",
    "    model=OPENAI_ADA_EMBEDDING_MODEL_NAME,\n",
    "    chunk_size=1,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    api_version=OPENAI_DEPLOYMENT_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pypdf import PdfReader\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "file_path = \".\\data\\BonBon FAQ.pdf\"\n",
    "reader = PdfReader(file_path)\n",
    "documents = [page.extract_text() for page in reader.pages]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup collection name and local data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "persist_directory = \"local_vectorstore\"\n",
    "local_store = \"local_docstore\"\n",
    "collection_name = \"react_agent\"\n",
    "try:\n",
    "    PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))\n",
    "except Exception:\n",
    "    PROJECT_ROOT = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load vector collection\n",
    "### Case 1: Vector collection doesn't exist -> Create new collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient(path = os.path.join(PROJECT_ROOT, \"data\", local_store))\n",
    "\n",
    "# Create a collection\n",
    "try:\n",
    "    client.delete_collection(collection_name)\n",
    "except:\n",
    "    print(f\"Collection '{collection_name}' did not exist\")\n",
    "collection = client.create_collection(collection_name)\n",
    "print(f\"Collection '{collection_name}' created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_i,doc in enumerate(documents):\n",
    "    chunks = text_splitter.split_text(doc)\n",
    "    for index, chunk in enumerate(chunks):\n",
    "        vector = embeddings.embed_query(chunk)  # Create an embedding for the document\n",
    "        collection.add(\n",
    "            ids=[chunk],\n",
    "            documents=[chunk],\n",
    "            embeddings=[vector],  # The vector representation\n",
    "            metadatas=[{\"page\": doc_i, \"source\": \"BonBon FAQ\"}]  # Optional metadata\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Load existing vector collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import chromadb\n",
    "client = chromadb.PersistentClient(path = os.path.join(PROJECT_ROOT, \"data\", local_store))\n",
    "\n",
    "# Create a collection\n",
    "collection = client.get_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vector store from collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma(client=client, collection_name=collection_name, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Building Chatbot (mandatory)\n",
    "- You are requested to build a chatbot solution for customer support scenario using Conversational ReAct agent supported in LangChain\n",
    "- The chatbot is able to support user to answer FAQs in the sample BonBon FAQ.pdf file.\n",
    "- The chatbot should use Azure Open AI GPT-3.5 LLM as the reasoning engine.\n",
    "- The chatbot should be context aware, meaning that it should be able to chat with users in the conversation manner.\n",
    "- The agent is equipped the following tools:\n",
    "  - Internet Search: Help the chatbot automatically find out more about something using Duck Duck Go internet search\n",
    "  - Knowledge Base Search: Help the chatbot to lookup information in the private knowledge base\n",
    "- In case user asks for information related to topics in the BonBon FAQ.pdf file such as internet connection, printer, malware issues the chatbot must use the private knowledge base, otherwise it should search on the internet to answer the question.\n",
    "- In the answer of chatbot, it should mention the source file and the page that the answer belongs to, for example the answer should mention \"BonBon FQA.pdf (page 2)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Tools for agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    Tool,\n",
    "    create_openai_tools_agent,\n",
    "    create_react_agent,\n",
    "    tool,\n",
    ")\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.chains import LLMMathChain, RetrievalQA\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "# Setting up ReAct Agent\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=OPENAI_MODEL_NAME,\n",
    "    model_name=OPENAI_MODEL_NAME,\n",
    "    azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    api_version=OPENAI_DEPLOYMENT_VERSION,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "doc_prompt = PromptTemplate.from_template(\n",
    "    \"<context>\\n{page_content}\\n\\n<meta>\\nsource: {source}\\npage: {page}\\n</meta>\\n</context>\"\n",
    ")\n",
    "tool_search = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"Search BonBon\",\n",
    "    description=\"Searches and returns answer from BONBON FAQ. Prioritize using this at least once.\",\n",
    "    document_prompt=doc_prompt,\n",
    ")\n",
    "\n",
    "math_chain = LLMMathChain.from_llm(llm=llm)\n",
    "duckduck = DuckDuckGoSearchRun()\n",
    "\n",
    "tools = [\n",
    "    tool_search,\n",
    "    Tool(\n",
    "        name=\"Duck Duck Go\",\n",
    "        func=duckduck.run,\n",
    "        description=\"useful for when you need to search for more information on the internet with Duck Duck Go search. Use this at most once for each input.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=math_chain.run,\n",
    "        description=\"use this tool for math calculating\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building ReAct agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the following questions as best you can. You can use history {history} to fill in unknown context. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "Remember: If any invalid format occurs, terminate and return answer\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, find in Search BonBon tool first, then should be one of [{tool_names}]. If not, terminate answer\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat at most 5 times.)\n",
    "Thought: I now know the final answer. Let's return the answer\n",
    "Final Answer: the final answer to the original input question. If use Search BonBon then include the page of the PDF file that has the question\n",
    "You should only tell the final answere\n",
    "Begin!\n",
    "Context:\n",
    "{entities}\n",
    "\n",
    "Current conversation:\n",
    "Chat History:\n",
    "{history}\n",
    "Last line:\n",
    "Human: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\"\n",
    "prompt_react = hub.pull(\"hwchase17/react\")\n",
    "prompt_react.template = template\n",
    "react_agent = create_react_agent(llm=llm, tools=tools, prompt=prompt_react)\n",
    "react_agent_executor = AgentExecutor(\n",
    "    agent=react_agent,\n",
    "    tools=tools,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True,\n",
    "    memory=ConversationEntityMemory(llm=llm, top_k=3),\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building chatbot that wrap around agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = input(\"enter prompt ('exit' to terminate): \")\n",
    "while i.lower() != \"exit\":\n",
    "    query = i\n",
    "    response = react_agent_executor.invoke({\"input\": query})\n",
    "    result = response.get(\"output\")\n",
    "    print(result)\n",
    "    i = input(\"enter new prompt ('exit' to terminate): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Build a new assistant based on BonBon source code (optional)\n",
    "The objective\n",
    "- Run the code and index the sample BonBon FAQ.pdf file to Azure Cognitive Search\n",
    "- Explore the code and implement a new assistant that has the same behavior as above\n",
    "- Explore other features such as RBACs, features on admin portal\n",
    "\n",
    "Please contact the training team in case you need to get the source code of BonBon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
